// train-cnn-augment.js
// Script para entrenar un modelo de clasificaci√≥n de im√°genes de basura
// usando TensorFlow.js con aumento de datos (data augmentation)

// Importar librer√≠as necesarias
import * as tf from "@tensorflow/tfjs-node"; // TensorFlow.js para Node.js
import fs from "fs"; // Sistema de archivos para leer im√°genes
import path from "path"; // Manejo de rutas de archivos

// Constantes de configuraci√≥n del modelo y dataset
const IMAGE_SIZE = 100; // Tama√±o al que se redimensionar√°n todas las im√°genes (100x100 p√≠xeles)
const DATA_DIR = "./data"; // Directorio donde est√°n las carpetas de cada clase de basura
const MODEL_DIR = "./models/image-classification"; // Directorio donde se guardar√° el modelo entrenado
const TEST_IMAGE = "./test_images/image-1.jpg"; // Imagen de prueba para validar el modelo

// === 1. Obtener clases ===
// Lee el directorio de datos y extrae las carpetas (cada carpeta es una clase de basura)
// Por ejemplo: cardboard, glass, metal, paper, plastic
const clases = fs
  .readdirSync(DATA_DIR) // Lee todos los elementos en el directorio de datos
  .filter((d) => fs.statSync(path.join(DATA_DIR, d)).isDirectory()); // Filtra solo los directorios
console.log("üì¶ Clases encontradas:", clases);

// === 2. Cargar im√°genes ===
// Funci√≥n as√≠ncrona que carga todas las im√°genes del dataset
// y las convierte en tensores (arrays multidimensionales) para TensorFlow
async function loadDataset() {
  const images = []; // Array para almacenar tensores de im√°genes
  const labels = []; // Array para almacenar las etiquetas (√≠ndice de clase)

  // Iterar sobre cada clase (cardboard=0, glass=1, metal=2, etc.)
  for (let i = 0; i < clases.length; i++) {
    const classDir = path.join(DATA_DIR, clases[i]); // Ruta completa a la carpeta de la clase
    const files = fs.readdirSync(classDir); // Leer todos los archivos de la carpeta

    // Procesar cada archivo de imagen en la carpeta
    for (const file of files) {
      const filePath = path.join(classDir, file); // Ruta completa del archivo
      const buffer = fs.readFileSync(filePath); // Leer el archivo como buffer binario

      // Decodificar y preprocesar la imagen
      const imgTensor = tf.node
        .decodeImage(buffer, 1) // Decodificar imagen en escala de grises (1 canal)
        .resizeNearestNeighbor([IMAGE_SIZE, IMAGE_SIZE]) // Redimensionar a 100x100 p√≠xeles
        .toFloat() // Convertir a n√∫meros flotantes
        .div(255.0); // Normalizar p√≠xeles de [0-255] a [0-1]

      images.push(imgTensor); // Agregar tensor de imagen al array
      labels.push(i); // Agregar √≠ndice de clase (0, 1, 2, etc.)
    }
  }

  // Convertir arrays de tensores a tensores apilados
  return {
    images: tf.stack(images), // Tensor 4D: [num_images, height, width, channels]
    labels: tf.tensor1d(labels, "int32"), // Tensor 1D: [num_images] con √≠ndices de clase
  };
}

// Cargar el dataset inicial
console.log("‚è≥ Cargando dataset...");
const { images, labels } = await loadDataset();
console.log(`‚úÖ ${images.shape[0]} im√°genes cargadas`);

// === 3. Funci√≥n de aumento de datos ===
// El aumento de datos (data augmentation) crea versiones modificadas de las im√°genes
// para aumentar artificialmente el tama√±o del dataset y mejorar la generalizaci√≥n del modelo
function augmentImage(img) {
  // img es un tensor de forma [height, width, channels]
  let out = img.reshape([1, IMAGE_SIZE, IMAGE_SIZE, 1]); // A√±adir dimensi√≥n de batch

  // Flip horizontal aleatorio (voltear imagen horizontalmente con 50% de probabilidad)
  // Esto ayuda al modelo a reconocer objetos independientemente de su orientaci√≥n
  if (Math.random() > 0.5) {
    out = tf.image.flipLeftRight(out);
  }

  // Random crop y resize (recorte y redimensionamiento aleatorio)
  // Simula zoom aleatorio entre 0.85x y 1.0x del tama√±o original
  const zoomFactor = 0.85 + Math.random() * 0.15; // Factor de zoom entre 0.85 y 1.0
  const cropSize = Math.floor(IMAGE_SIZE * zoomFactor); // Tama√±o del recorte
  const offsetY = Math.floor(Math.random() * (IMAGE_SIZE - cropSize)); // Offset vertical aleatorio
  const offsetX = Math.floor(Math.random() * (IMAGE_SIZE - cropSize)); // Offset horizontal aleatorio

  // Recortar y redimensionar la imagen
  out = tf.image.cropAndResize(
    out,
    [
      [
        offsetY / IMAGE_SIZE, // Coordenada Y superior normalizada
        offsetX / IMAGE_SIZE, // Coordenada X izquierda normalizada
        (offsetY + cropSize) / IMAGE_SIZE, // Coordenada Y inferior normalizada
        (offsetX + cropSize) / IMAGE_SIZE, // Coordenada X derecha normalizada
      ],
    ],
    [0], // √çndice del batch
    [IMAGE_SIZE, IMAGE_SIZE] // Tama√±o final despu√©s del resize
  );

  // Ajuste de brillo aleatorio multiplicando por un factor entre 0.85 y 1.15
  // Esto simula diferentes condiciones de iluminaci√≥n
  const brightnessFactor = 0.85 + Math.random() * 0.3; // Factor de brillo
  out = out.mul(brightnessFactor).clipByValue(0, 1); // Multiplicar y mantener valores entre 0 y 1

  // Devolver el tensor con forma original [IMAGE_SIZE, IMAGE_SIZE, 1]
  return out.reshape([IMAGE_SIZE, IMAGE_SIZE, 1]);
}

// === 4. Generar dataset aumentado ===
// Esta funci√≥n aplica aumento de datos a todas las im√°genes del dataset original
// y combina las im√°genes originales con las aumentadas para duplicar el tama√±o del dataset
function augmentDataset(images, labels) {
  const augmentedImages = []; // Array para las im√°genes aumentadas
  const augmentedLabels = []; // Array para las etiquetas de las im√°genes aumentadas

  const num = images.shape[0]; // N√∫mero total de im√°genes originales

  // Procesar cada imagen del dataset original
  for (let i = 0; i < num; i++) {
    // Extraer una sola imagen del tensor 4D
    const img = images
      .slice([i, 0, 0, 0], [1, IMAGE_SIZE, IMAGE_SIZE, 1]) // Extraer imagen i
      .squeeze(); // Eliminar dimensi√≥n de batch (de [1,100,100,1] a [100,100,1])
    const label = labels.arraySync()[i]; // Obtener la etiqueta de clase para esta imagen

    // Aplicar transformaciones de aumento de datos
    const augmented = augmentImage(img);
    augmentedImages.push(augmented); // Guardar imagen aumentada
    augmentedLabels.push(label); // Guardar la misma etiqueta
  }

  // Combinar im√°genes originales y aumentadas en un solo dataset
  const allImages = tf.concat([images, tf.stack(augmentedImages)]); // Concatenar tensores
  const allLabels = tf.concat([labels, tf.tensor1d(augmentedLabels, "int32")]); // Concatenar etiquetas
  return { allImages, allLabels };
}

// Aplicar aumento de datos al dataset original
console.log("üîÅ Aplicando aumento de datos...");
const { allImages, allLabels } = augmentDataset(images, labels);
console.log(`‚ú® Dataset aumentado: ${allImages.shape[0]} im√°genes totales`);

// === 5. Convertir labels a one-hot encoding ===
// One-hot encoding convierte √≠ndices de clase (0,1,2,3,4) a vectores binarios
// Por ejemplo: clase 2 con 5 clases ‚Üí [0, 0, 1, 0, 0]
// Esto es necesario para la funci√≥n de p√©rdida categorical crossentropy
const allLabelsOneHot = tf.oneHot(allLabels, clases.length);

// === 6. Dividir dataset (85% - 15%) ===
// Separar el dataset en conjunto de entrenamiento y validaci√≥n
// Training: 85% - para entrenar el modelo
// Validation: 15% - para evaluar el rendimiento durante el entrenamiento
const total = allImages.shape[0]; // Total de im√°genes en el dataset aumentado
const trainSize = Math.floor(total * 0.85); // 85% para entrenamiento
const valSize = total - trainSize; // 15% para validaci√≥n

// Dividir im√°genes en train y validation
const [imagesTrain, imagesVal] = tf.split(allImages, [trainSize, valSize]);
// Dividir etiquetas en train y validation
const [labelsTrain, labelsVal] = tf.split(allLabelsOneHot, [
  trainSize,
  valSize,
]);
console.log(`üìä Train: ${trainSize}, Validaci√≥n: ${valSize}`);

// === 7. Crear modelo CNN (Red Neuronal Convolucional) ===
// El modelo Sequential permite apilar capas una tras otra
const model = tf.sequential();

// Primera capa convolucional
// - inputShape: [100, 100, 1] - im√°genes de 100x100 p√≠xeles en escala de grises
// - filters: 32 - aprende 32 filtros/caracter√≠sticas diferentes
// - kernelSize: 3 - cada filtro es de 3x3 p√≠xeles
// - activation: 'relu' - funci√≥n de activaci√≥n ReLU (introduce no-linealidad)
model.add(
  tf.layers.conv2d({
    inputShape: [IMAGE_SIZE, IMAGE_SIZE, 1],
    filters: 32,
    kernelSize: 3,
    activation: "relu",
  })
);
// Capa de max pooling - reduce dimensiones tomando el valor m√°ximo en ventanas de 2x2
// Esto reduce el tama√±o de la imagen a la mitad y ayuda a detectar caracter√≠sticas invariantes a la posici√≥n
model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

// Segunda capa convolucional
// - filters: 64 - aprende caracter√≠sticas m√°s complejas con 64 filtros
model.add(tf.layers.conv2d({ filters: 64, kernelSize: 3, activation: "relu" }));
// Segunda capa de max pooling
model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

// Tercera capa convolucional
// - filters: 128 - aprende caracter√≠sticas a√∫n m√°s abstractas con 128 filtros
model.add(
  tf.layers.conv2d({ filters: 128, kernelSize: 3, activation: "relu" })
);
// Tercera capa de max pooling
model.add(tf.layers.maxPooling2d({ poolSize: 2 }));

// Capa flatten - convierte el tensor 3D en un vector 1D para las capas densas
model.add(tf.layers.flatten());

// Capa de dropout - desactiva aleatoriamente 30% de las neuronas durante entrenamiento
// Esto previene el overfitting (sobreajuste) al forzar al modelo a no depender de neuronas espec√≠ficas
model.add(tf.layers.dropout({ rate: 0.3 }));

// Capa densa (fully connected) con 100 neuronas
// Aprende combinaciones complejas de las caracter√≠sticas extra√≠das por las capas convolucionales
model.add(tf.layers.dense({ units: 100, activation: "relu" }));

// Capa de salida - una neurona por cada clase
// - units: n√∫mero de clases (cardboard, glass, metal, paper, plastic)
// - activation: 'softmax' - convierte las salidas en probabilidades que suman 1
model.add(tf.layers.dense({ units: clases.length, activation: "softmax" }));

// Compilar el modelo con configuraci√≥n de optimizaci√≥n y m√©tricas
model.compile({
  optimizer: tf.train.adam(), // Optimizador Adam - algoritmo de descenso de gradiente adaptativo
  loss: "categoricalCrossentropy", // Funci√≥n de p√©rdida para clasificaci√≥n multiclase
  metrics: ["accuracy"], // M√©trica a monitorear: precisi√≥n (accuracy)
});

// === 8. Entrenamiento ===
// Entrenar el modelo con los datos de entrenamiento
console.log("üöÄ Entrenando modelo...");
await model.fit(imagesTrain, labelsTrain, {
  epochs: 30, // N√∫mero de √©pocas - cu√°ntas veces el modelo ver√° todo el dataset (ajustable)
  batchSize: 32, // Tama√±o del batch - procesa 32 im√°genes a la vez antes de actualizar pesos
  validationData: [imagesVal, labelsVal], // Datos de validaci√≥n para evaluar en cada √©poca
  shuffle: true, // Mezclar datos en cada √©poca para evitar sesgos de orden
  callbacks: {
    // Callback que se ejecuta al final de cada √©poca
    onEpochEnd: (epoch, logs) => {
      // Mostrar progreso: n√∫mero de √©poca, p√©rdida y precisi√≥n en validaci√≥n
      console.log(
        `Epoch ${epoch + 1}: loss=${logs.loss.toFixed(4)}, val_acc=${(
          logs.val_acc ||
          logs.val_accuracy ||
          0
        ).toFixed(4)}`
      );
    },
  },
});

// === 9. Evaluaci√≥n ===
// Evaluar el modelo entrenado con el conjunto de validaci√≥n
const evalResult = model.evaluate(imagesVal, labelsVal);
// Obtener los valores de p√©rdida y precisi√≥n
const [lossArray, accArray] = await Promise.all(
  evalResult.map((x) => x.data())
);
const loss = lossArray[0]; // P√©rdida final
const acc = accArray[0]; // Precisi√≥n final
console.log(`üìâ P√©rdida: ${loss?.toFixed(4)}, Precisi√≥n: ${acc?.toFixed(4)}`);

// === 10. Guardar modelo ===
// Guardar el modelo entrenado en el sistema de archivos
// El modelo se guarda en formato JSON junto con los pesos en archivos binarios
await model.save(`file://${MODEL_DIR}`);
console.log(`‚úÖ Modelo guardado en ${MODEL_DIR}`);

// === 11. Predicci√≥n ===
// Funci√≥n para hacer predicciones sobre nuevas im√°genes
async function predictImage(imgPath) {
  const buffer = fs.readFileSync(imgPath); // Leer imagen de prueba

  // Preprocesar la imagen de la misma manera que las im√°genes de entrenamiento
  const img = tf.node
    .decodeImage(buffer, 1) // Decodificar en escala de grises
    .resizeNearestNeighbor([IMAGE_SIZE, IMAGE_SIZE]) // Redimensionar a 100x100
    .toFloat() // Convertir a flotante
    .div(255.0) // Normalizar a [0, 1]
    .expandDims(0); // A√±adir dimensi√≥n de batch: [1, 100, 100, 1]

  // Hacer la predicci√≥n
  const pred = model.predict(img); // Obtener probabilidades para cada clase
  const labelIndex = pred.argMax(-1).dataSync()[0]; // Obtener √≠ndice de la clase con mayor probabilidad
  console.log(`üñºÔ∏è Clase predicha: ${clases[labelIndex]}`); // Mostrar nombre de la clase
  return clases[labelIndex]; // Devolver el nombre de la clase
}

// Probar el modelo con una imagen de prueba
await predictImage(TEST_IMAGE);
